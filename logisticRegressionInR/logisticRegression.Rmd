---
title: "Logistic Regression"
output: html_notebook
---
##### NICAR 2018, Chicago Illinois
##### Hannah Fresques 

```{r message=FALSE}
library(dplyr)
library(ggplot2)
library(readr)
library(broom)
library(stringr)
```

#### Regression

Many of the most fascinating questions we ask as journalists are about the relationships between different variables. Regression is the art and the science of finding relationships in the way two or more variables interact.

Let's start by familiarizing ourselves with the data.

```{r}
schools <- read_rds("data/schools.rds") # 3796
schools <- schools %>% na.omit() %>% filter(str_trim(type) %in% c("ELEMENTARY","MIDDLE SCHL")) # 2835
schools <- schools %>% 
  mutate(
    CHI=ifelse(CHI==T,"Chicago","Rest of IL"),
    CHI=factor(CHI,levels=c("Rest of IL","Chicago")),
    failed=!(didWell)
  )
schools %>% head(30) %>% View()
schools %>% count(type)
schools %>% count(CHI)
schools %>% filter(CHI=="Chicago") %>% count(city,county)
schools %>% group_by(didWell) %>% summarize(min=min(PARCCpct), max=max(PARCCpct))
schools %>% select(contains("pct")) %>% summary()
```

In this data there is one row per Illinois school, which includes characteristics of the school and PARCC test proficiency rates. (The data is from [here](https://www.isbe.net/pages/illinois-state-report-card-data.aspx)). The PARCC is administered to students in 3rd-8th grades.

Let's plot the relationship between the percent low income variable and the percent of students who get a proficient score on the PARCC.

```{r}
a <- ggplot(schools,aes(x=pctLowInc,y=PARCCpct))
a + geom_point()
```

This is known as a scatter plot. Each circle on the chart represents a school that appears in the data. The horizontal x-axis represents the percent of low income students at the school. The vertical y-axis represents the percent of students who were deemed proficient on the PARCC test.

It's clearly not perfect, but there does appear to be a discernible pattern here where as a school has more low income students, their proficiency rate tends to go down.

Linear regression is asking R to do the best job it can finding a line that predicts y for a given value of x. 

Let's do that visually first.


```{r}
a + geom_point() + geom_smooth(method="lm", se=FALSE)
```

The line is the result of R doing the best job it can generalizing the relationship between the two variables we've put in. (For a more technical description of this, go [here](https://en.wikipedia.org/wiki/Ordinary_least_squares).

What we can see here is that the relationship between the two variables is _negative_. That means that as the percent of low income students  goes up, proficiency rates go down. But even better than knowing that would be putting a number on that decrease. To do that, we need to have R generate an actual equation for us.

You may remember back to middle school. The change in Y per an increase in X is called the _slope_ of the line. Sometimes it's also called _rise over run_. The formula is:

$$y=\beta _{0}+\beta _{1}x$$


If none of this sounds familiar to you, that's okay too.

Let's have R generate our equation using the 'lm' function, which stands for linear model.
```{r}
inc_model <- lm(PARCCpct~pctLowInc, schools)
summary(inc_model)
```

The value in linear regression output that expresses the _amount_ of change associated with an explainer variable is called a 'coefficient'. In a linear regression, the __coefficient__ is in the same units as the variables themselves.

So, in this case, a one-percentage-point increase in low income students is associated with a 0.48 percentage point decrease in proficiency rates. A finding!

Before we go nuts, though, we also want to look at a couple of other pieces of information from the regression output.

The $Pr(>|t|)$ value tells us whether the increase or decrease described in the coefficient is statistically significant. The level of significance expresses our confidence in our result. If a coefficient is not statistically significant, it means we can't rule out that the effect we're seeing is due to chance. Statistically insignificant doesn't necessarily mean no effect. It often just means there is not enough data to draw a strong conclusion. And statistically significant doesn't necessarily mean you have an interesting effect. With a lot of data, a very small coefficient may be statistically significant. It's up to you to decide if the coefficient is meaningfully large.

The standard level of significance is 95%, which means we want a $Pr(>|t|)$ value of less than .05.  In case that's hard to remember, R also has a star rating system indicating significance. If you have one or more $*$ next to your coefficient's p-value, your result is significant at the 95% level.

The final value worth checking out is the __Adjusted R-squared__. This is a value between 0 and 1 that expresses, simply put, how much of the variation we see in Y is explained by X. An R-squared value of 1 would mean that we can perfectly predict a school's PARCC proficiency based on the percent of low income students at the school. An R-Squared value of 0 means that the variables in our model overall don't explain any of the variation we see in test scores.

There is always much discussion about what a "good" R-squared value is. In general, higher is better, but a result can still be interesting even if the R-squared is modest, especially if the relationship is unexpected in some way. E.g. Prayer has been shown to marginally improve life-expectancy after cancer diagnosis. Clearly prayer is not the most explanatory factor, but the fact that it has any effect at all is interesting.

Let's try another one:

Is the race of students at a school related to the school's proficiency score? Let's see.

```{r}
b <- ggplot(schools,aes(x=pctBlack,y=PARCCpct))
b + geom_point() + geom_smooth(method="lm", se=FALSE)
```


Schools with more black students have lower PARCC proficiency rates.

Seeing this trend, is there anything you want to reconsider in our first linear model?

```{r}
c <- ggplot(schools,aes(x=pctBlack,y=pctLowInc))
c + geom_point() + geom_smooth(method="lm", se=FALSE)
```

One last one. How do Chicago schools compare to the rest of Illinois?

```{r}
schools %>% group_by(CHI) %>% summarize(PARCCpct=mean(PARCCpct))
```
```{r}
CHI_model <- lm(PARCCpct~CHI, schools)
summary(CHI_model)
```

Scores are lower in Chicago.

```{r}
schools %>% group_by(CHI) %>% summarize(pctBlack=mean(pctBlack))
```

Chicago schools have more black students than other schools in the state.


```{r}
d <- ggplot(schools,aes(x=pctBlack,y=PARCCpct))
d + geom_point() + geom_smooth(method="lm", se=FALSE) + facet_wrap(~CHI)
```



#### Multivariate regression

So far, we've limited ourselves to one variable at a time. But _why?_

We can put in more than one (although at the point we can't really keep visualizing easily.)

The convention for this in R is :

outcome ~ explainer variable1 + explainer variable2 + ...+ explainer variableN

```{r}
multi_model <- lm(PARCCpct~pctBlack+pctLowInc+CHI, schools)
summary(multi_model)
```

Let's look at this output.

You'll notice that each variable we included in the model has its own coefficient. Which ones are large and which are small? Which are statistically significant? What happened to our R-squared value?

_How do I decide what to include?_

It may be tempting to just throw in everything. Don't! Generally accepted best practice is to carefully choose a handful of variables. Experts might use their own subject knowledge or other research to inform their decisions. As journalists, it's a great idea to use reporting (including talking to experts) to decide. 


#### Risk and Odds

Until now we've been predicting a variable that is continuous. A percent can be many different values. But often we find ourselves wanting to model an up-or-down outcome like, death, graduation, a guilty verdict, getting hired for a job. These are all variables with only two values, yes and no.

Not to worry - this is what logistic regression can do for us.

What if we were instead interested in schools that failed to pass a certain proficiency benchmark, say schools that did worse than the state average?

First let's look to see how Chicago schools did compared to the rest of the state.

```{r}
schools %>% count(CHI,failed)  
```

The failure rate for Chicago schools will be the schools that were below the benchmark divided by the total number of schools.
```{r}
322/(94+322)
```
The failure rate for non-Chicago schools:
```{r}
1215/(1215+1204)
```

These are measures of *risk*

risk = successes / (successes + failures)

If want to know the _relative_ failure rates of Chicago and non-Chicago schools, we need to calculate something called a risk ratio. Here we do that by dividing the Chicago failure rate by the non-Chicago failure rate.

```{r}
.77/.50
```

We can describe this result by saying that Chicago schools were about 54% more likely to fail than schools in the rest of the state.

So far so good, but we are only looking at part of the picture. To include more variables, we will need to run a logistic regression. 

But first, a detour into the odd world of odds.

Risk, as we saw above, is what we usually use to talk about how often some event happens. But sometimes we use odds instead. They are common in sports and gambling. 

odds = successes / failures

Using the example above, the odds of a Chicago school being below the benchmark is:

```{r}
322/94
```
The odds of failure for non-Chicago schools:
```{r}
1215/1204
```

If want to know the _relative_ odds of Chicago and non-Chicago schools, we calculate an odds ratio. Here we do that by dividing the Chicago odds by the non-Chicago odds.

```{r}
(322/94)/(1215/1204)
```

To put this into words: The odds of a Chicago school failing to meet the benchmark are more than three times the odds of failing for a school outside of Chicago.  

You may be wondering why anyone would ever use odds. They are harder to talk about and kind of confusing. One big reason is that the results of logistic regression can only be expressed in odds.



#### Logistic regression

Logistic regression uses the same principals as linear regression. But it uses a 'link function' to transform the predicted outcome variable from any real number to a number between 0 and 1.

$$y={\frac {1}{1+e^{-(\beta _{0}+\beta _{1}x)}}}$$

To actually run a logistic regression, the syntax is similar to the linear model syntax above:

```{r}
logistic_model <- glm(
    failed ~ CHI,
    data = schools,
    family = 'binomial'
)
summary(logistic_model)
```

As before, we look at the coefficients. But this time, they are not in the same units as what we're trying to predict. They are in something called log-odds. (To see how the link function above and the definition of odds all come together, see [here](https://en.wikipedia.org/wiki/Logistic_regression).)

Let's look at the coefficient for CHI.
```{r}
logistic_model %>% tidy() %>% filter(term=="CHIChicago") %>% select(estimate)
```
```{r}
logistic_model %>% tidy() %>% filter(term=="CHIChicago") %>% select(estimate) %>% exp()
```

Once we exponentiate it, we can see that the coefficient is equal to the odds ratio we calculated above. Generally, when reporting coefficients from a logistic regression, want to express our result in odds and not log-odds.

As with linear regression, we can add additional variables to the model. 

```{r}
multi_logistic_model <- glm(
    failed ~ CHI + pctBlack + pctLowInc + type,
    data = schools,
    family = 'binomial'
)
summary(multi_logistic_model)
```


```{r}
multi_logistic_model %>% tidy() %>% filter(term=="CHIChicago") %>% select(estimate) 
```
```{r}
multi_logistic_model %>% tidy() %>% filter(term=="CHIChicago") %>% select(estimate) %>% exp()
```

Once we control for demographic characteristics of schools, we see that Chicago schools are *less* likely to fail to meet the benchmark. For Chicago schools, the odds of failing are only 13% of the odds for a school elsewhere in the state, controlling for demographics.

Now let's look at income:
```{r}
multi_logistic_model %>% tidy() %>% filter(term=="pctLowInc") %>% select(estimate) 
```
```{r}
multi_logistic_model %>% tidy() %>% filter(term=="pctLowInc") %>% select(estimate) %>% exp()
```

For a one percentage point increase in low income students at a school, the odds of failing to meet the benchmark increase by 9%.

The R star-rating system holds true here as well - if a coefficient has at least one star, you've met the 95% confidence level requirement for statistical significance.

VERY IMPORTANT to remember: You cannot treat odds like risk. They are not the same thing. You need to make sure you use the right terminology when you talk about your results. You can convert odds to risk for certain parameters in your model, but that's beyond the scope of this presentation, and comes with its own set of caveats.
