---
title: "R Notebook"
output: html_notebook
---
##### NICAR 2018
##### Hannah Fresques 

```{r message=FALSE}
library(dplyr)
library(ggplot2)
library(readr)

library(tidyr)
library(nlme)
library(tibble)
library(broom)

```

#### Regression

Many of the most fascinating questions we ask as journalists are about the relationships between different variables. Regression is the art and the science of finding relationships in the way two or more variables interact.

Let's start by familiarizing ourselves with the data.

```{r}
schools <- read_rds("data/schools.rds")
schools %>% head(30) %>% View()
```

In this data there is one row per Illinois school, which includes characteristics of the school and PARCC test proficiency rates. (The data is from [here](https://www.isbe.net/pages/illinois-state-report-card-data.aspx))

Let's plot the relationship between the verbal IQ variable and the language test score.

```{r}
a <- ggplot(schools,aes(pctLowInc,PARCCpct))
a + geom_point()
```

This is known as a scatterplot. Each circle on the chart represents a school that appears in the data. The horizontal x-axis represents the percent of low income students at the school. The vertical y-axis represents the percent of students who were demed proficient on the PARCC test.

It's clearly not perfect, but there does appear to be a discernible pattern here where as a school has more low income students, their proficiency rate tends to go down.

Linear regression is asking R to do the best job it can finding a line that predicts y for a given value of x. 

Let's do that visually first.


```{r}
a + geom_point() + geom_smooth(method="lm")
```

The line is the result of R doing the best job it can generalizing the relationship between the two variables we've put in. (For a more technical description of this, go [here](https://en.wikipedia.org/wiki/Ordinary_least_squares).

What we can see here is that the relationship between the two variables is _negative_. That means that as the percent of low income students  goes up, proficiency rates go down. But even better than knowing that would be putting a number on that increase. To do that, we need to have R generate an actual equation for us.

You may remember back to middle school. The change in Y per an increase in X is called the _slope_ of the line. Sometimes it's also called _rise over run_. The formula is:

$y=mx+b$

If none of this sounds familiar to you, that's okay too.

Let's have R generate our equation using the 'lm' function, which stands for linear model.
```{r}
inc_model <- lm(PARCCpct~pctLowInc, schools)
summary(inc_model)
```

The value in linear regression output that expresses the _amount_ of change associated with an explainer variable is called a 'coefficient'. In a linear regression, the __coefficient__ is in the same units as the variables themselves.

So, in this case, a one-percentage-point increase in low income students is associated with a 0.47 point decrease in proficiency rates. A finding!

Before we go nuts, though, we also want to look at a couple of other pieces of information from the regression output.

The $Pr(>|t|)$ value tells us whether the increase or decrease described in the coefficient is statistically significant. The level of significance expresses our confidence in our result. If a coefficient is not statistically significant, it means we can't rule out that the effect we're seeing is due to chance. Statistically insignificant doesn't necessarily mean no effect. It often just means there is not enough data to draw a strong conclusion.

The standard level of significance is 95%, which means we want a $Pr(>|t|)$ value of less than .05.  In case that's hard to remember, R also has a star rating system indicating significance. If you have one or more $*$ next to your coefficient's p-value, your result is significant at the 95% level.

The final value worth checking out is the __Adjusted R-squared__. This is a value between 0 and 1 that expresses, simply put, how much of the variation we see in Y is explained by X. An R-squared value of 1 would mean that we can perfectly predict a child's test score based on their measured IQ. An R-Squared value of 0 means that the variables in our model overall don't explain any of the variation we see in test scores.

There is always much discussion about what a "good" R-squared value is. In general, higher is better, but a result can still be interesting even if the R-squared is modest, especially if the relationship is unexpected in some way. E.g. Prayer has been shown to marginally improve life-expectancy after cancer diagnosis. Clearly prayer is not the most explanatory factor, but the fact that it has any effect at all is interesting.

Let's try another one:

```{r}
b <- ggplot(schools,aes(pctBlack,PARCCpct))
b + geom_point()
```

Knowing what we know about American education, the expectation would be that the more black students attend a school, the lower the proficiency rate at the school. Let's find out if this is the case.

```{r}
b + geom_point() + geom_smooth(method="lm")
```

TKTK EDITS NEEDED HERE.

Meetings don't seem to have any effect at all. Perhaps we need to refine our approach. Let's draw separate lines for minority and non-minority students.

```{r}
c <- ggplot(schools,aes(pctBlack,pctLowInc))
c + geom_point() + geom_smooth(method="lm")
# a <- ggplot(bdf,aes(meetings,langPOST,color=Minority))
# a + geom_point() + geom_smooth(method="lm") + facet_wrap(~Minority)
```

It suggests that while intervention in the form of meetings has little to no effect for non-minority students, but in the Dutch school system, it translates to higher test scores. Let's filter our data and run a linear regression on just our minority students.

```{r}
minority_scores <- bdf %>% filter(Minority=='Y')
min_meeting_model <- lm(langPOST~meetings,minority_scores)
summary(min_meeting_model)
```

Hey class: what can we learn from this regression output? What might we want to be wary of?

#### Multivariate regression
So far, we've limited ourselves to one variable at a time. But _why?_

We can put in more than one (although at the point we can't really keep visualizing easily.)

The convention for this in R is :

outcome ~ explainer variable1 + explainer variable2 + ...+ explainer variableN

```{r}
multi_model <- lm(PARCCpct~pctBlack+pctLowInc, schools)
summary(multi_model)
```

Let's look at this output.

You'll notice that each variable we included in the model has its own coefficient. Which ones are large and which are small? Which are statistically significant? What happened to our R-squared value?

_How do I decide what to include?_

It may be tempting to just throw in everything. Don't! Generally accepted best practice is to carefully choose a handful of variables. Experts might use their own subject knowledge or other research to inform their decisions. As journalists, it's a great idea to use reporting (including talking to experts) to decide. 

#### Logistic regression
Until now we've been predicting a variable that is continuous. A score can be many different values. But often we find ourselves wanting to model an up-or-down outcome like, death, graduation, a guilty verdict, getting hired for a job. These are all variables with only two values, yes and no.

Not to worry - this is what logistic regression can do for us.

What if we were instead interested in schools that met a certain proficency benchmark, say schools that did better than the state average.

First let's look to see how Chicago schools did compared to the rest of the state.

```{r}
schools %>% filter(is.na(didWell)==F) %>% count(CHI,didWell)  
```

The pass rate for Chicago schools will be the schools that met our criteria divided by the total number of schools.
```{r}
109/(109+384)
```
The pass rate for non-Chicago schools:
```{r}
1221/(1221+1271)
```

If want to know the _relative_ pass rates of Chicago and non-Chicago schools, we need to calculate something called a risk ratio. Here we do that by dividing the Chicago pass rate by the non-Chicago pass rate.

```{r}
.22/.49
```

We can describe this result by saying that Chicago schools were about 30% less likely to die than adults.

So far so good, but we are only looking at part of the picture. To include more variables, we will need to run a logistic regression. 

The syntax is not dissimilar from the linear model syntax above:

```{r}
logistic_model <- glm(
    didWell ~ CHI + pctBlack + pctLowInc + type,
    data = schools,
    family = 'binomial'
)
summary(logistic_model)
```

As before, we look at the coefficients. But this time, they are not in the same units as what we're trying to predict. They are in something called log-odds. Under certain circumstances, we can interpret them as reduced or increased likelihood of the event we're trying to predict relative to a reference category.

For example, we have coefficients for Class2nd and Class3rd, but not Class1st. The -1.02 coefficient means that the log-odds are relative to first class passengers. We also want to express our result in odds and not log-odds (that's confusing).

Let's work through an example. The log-odds of dying for a 3rd-class passenger relative to a 1st-class passenger, controlling for passenger sex and age, are:

```{r}
# exp(1.7778)
logistic_model %>% tidy() %>% filter(term=="CHITRUE") %>% select(estimate)
logistic_model %>% tidy() %>% filter(term=="CHITRUE") %>% select(estimate) %>% exp()
```

So the odds of dying for a poor passenger were almost 6 times the odds of dying for a well-to-do passenger.

Now let's look at the gap between adults and children:
```{r}
exp(1.0615)
```

The odds of an adult dying were nearly three times that of a child dying.

The R star-rating system holds true here as well - if a coefficient has at least one star, you've met the 95% confidence level requirement for statistical significance.

The VERY IMPORTANT catch: You cannot treat odds like risk. They are not the same thing. You need to make sure you use the right terminology when you talk about your results. You can convert odds to risk for certain parameters in your model, but that's beyond the scope of this presentation, and comes with its own set of cavieats.







